[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fredusho/data-science-portfolio/blob/main/redes-neuronales-renuncia-telecomunicciones/renuncia-telecomunicaciones.ipynb)

# PredicciÃ³n de Renuncia de Clientes en Telecomunicaciones ğŸ“¡ğŸ“‰

## ğŸ§© DescripciÃ³n del proyecto
El objetivo de este proyecto es **predecir la renuncia (churn)** de clientes de una empresa de telecomunicaciones utilizando modelos de **aprendizaje supervisado**, con enfoque en **Ã¡rboles de decisiÃ³n y tÃ©cnicas de ensamble** como **Bagging** y **Random Forest**.

Se desarrolla un flujo completo de anÃ¡lisis exploratorio, correlaciones, selecciÃ³n de variables, modelado, optimizaciÃ³n de hiperparÃ¡metros y validaciÃ³n.

---

## âš™ï¸ TecnologÃ­as y librerÃ­as utilizadas
- Python 3.10+
- pandas / numpy
- seaborn / matplotlib
- scikit-learn
- Google Colab

---

## ğŸ§  Objetivos principales
1. Analizar los factores que influyen en la renuncia de clientes.
2. Entrenar un modelo predictivo para identificar clientes en riesgo.
3. Mejorar los modelos con tÃ©cnicas de ensamble y tunning (GridSearchCV).
4. Evaluar el modelo mediante mÃ©tricas de clasificaciÃ³n (Accuracy, F1-Score).
5. Identificar los clientes con mayor probabilidad de abandono.

---

## ğŸ“Š Flujo analÃ­tico y resultados

### ğŸ”¹ Modelo Ãrbol de DecisiÃ³n (bÃ¡sico)
- **Accuracy:** 0.892
- Evidente **overfitting** (100% en entrenamiento vs 89% en test)

### ğŸ”¹ Ãrbol de DecisiÃ³n optimizado (GridSearchCV)
- **Accuracy:** 0.905
- Mejor generalizaciÃ³n â†’ sobreajuste controlado

### ğŸ”¹ Bagging heterogÃ©neo
- **Accuracy:** 1.000
- **F1-score:** 1.000  
- ClasificaciÃ³n perfecta en test

### ğŸ”¹ Random Forest (modelo final)
- **Accuracy en test:** **1.000**
- **F1-score:** **1.000**
- **OOB Score:** 0.943 (confirmando buena generalizaciÃ³n)
- Variables mÃ¡s importantes:
  1. CustServCalls
  2. DayMins
  3. MonthlyCharge
  4. AccountWeeks

ğŸ“Œ Insights clave:  
- Clientes con **alto uso de minutos**, **mayor facturaciÃ³n** y **mÃ¡s llamadas a soporte** son los que mÃ¡s renuncian.
- El modelo permite **detectar riesgo temprano** y aplicar estrategias de retenciÃ³n.

---

## ğŸ¯ Conclusiones
- Los modelos basados en ensamble (**Random Forest y Bagging**) obtuvieron el mejor desempeÃ±o.
- Se logrÃ³ una predicciÃ³n perfecta en test en este dataset.
- Se recomienda monitorear el **desbalance de clases** y utilizar mÃ©tricas mÃ¡s estrictas en escenarios reales.
- Los Ã­ndices de importancia facilitan el **diseÃ±o de campaÃ±as de retenciÃ³n** enfocadas en clientes crÃ­ticos.
