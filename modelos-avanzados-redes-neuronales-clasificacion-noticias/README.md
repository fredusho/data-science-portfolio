
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fredusho/data-science-portfolio/blob/main/modelos-avanzados-redes-neuronales-clasificacion-noticias/clasificacion-noticias.ipynb)

# ClasificaciÃ³n de Noticias â€” Fake vs Real ğŸ“°ğŸ§ 

## ğŸ§© DescripciÃ³n del proyecto
Este proyecto, correspondiente al examen final del mÃ³dulo de Procesamiento de Lenguaje Natural (NLP), tiene como objetivo **detectar noticias falsas** mediante tÃ©cnicas de aprendizaje profundo.

Se desarrolla un flujo completo:
âœ… Preprocesamiento de texto  
âœ… Embeddings Word2Vec preentrenados  
âœ… Entrenamiento de una **Red Neuronal LSTM Bidireccional**  
âœ… EvaluaciÃ³n en datos no vistos  
âœ… PredicciÃ³n final entregable

---

## âš™ï¸ TecnologÃ­as y librerÃ­as utilizadas
- Python 3.10+
- pandas / numpy
- nltk / re / WordCloud
- TensorFlow Â· Keras (Bidirectional LSTM)
- scikit-learn
- Google Colab

---

## ğŸ§  Objetivos principales
1. Tratar y limpiar texto eliminando ruido lingÃ¼Ã­stico
2. Representar palabras como vectores usando **Word2Vec (Google News 300d)**
3. Entrenar modelo secuencial con dropout preventivo
4. Predecir nuevas noticias (entrega final)
5. Evaluar con mÃ©tricas de clasificaciÃ³n y curvas ROC

---

## ğŸ§¹ Preprocesamiento aplicado
- ConversiÃ³n a minÃºsculas
- EliminaciÃ³n de puntuaciones, nÃºmeros y sÃ­mbolos
- TokenizaciÃ³n paso a paso
- LemmatizaciÃ³n & stopwords NLTK
- Secuencias padded â†’ entradas uniformes

---

## ğŸ¤– Modelado y evaluaciÃ³n

### ğŸ“Œ Modelo Final: Bidirectional LSTM
- Early Stopping para evitar sobreajuste
- Capas densas con activadores ReLU y Sigmoid

| MÃ©trica | Valor |
|--------|------|
| **Accuracy** | **92.12%** |
| AUC ROC | **> 0.90 (Excelente)** |

ğŸ“Œ El modelo discrimina claramente entre noticias reales y falsas âœ…

---

## ğŸ” AnÃ¡lisis adicional
- WordCloud y frecuencia de tÃ©rminos
- PolÃ­ticas â†’ alta fuente de error por contenido ambiguo
- El modelo puede integrarse en pipelines reales de detecciÃ³n de desinformaciÃ³n

---
