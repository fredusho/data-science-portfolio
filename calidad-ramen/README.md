[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fredusho/data-science-portfolio/blob/main/calidad-ramen/clasificacion-calidad-ramen.ipynb)

# ClasificaciÃ³n de Calidad de Ramen ğŸœ

## ğŸ§© DescripciÃ³n del proyecto
Este proyecto aborda la **clasificaciÃ³n de la calidad de ramen** en funciÃ³n de sus caracterÃ­sticas (marca, paÃ­s, estilo, entre otros) mediante tÃ©cnicas de **aprendizaje supervisado**.  
Se busca construir un modelo capaz de predecir si un ramen es **"Good" (bueno)** o **"Bad" (malo)** segÃºn sus valoraciones, utilizando un conjunto de datos con mÃ¡s de 2.500 observaciones de productos evaluados.

---

## âš™ï¸ TecnologÃ­as y librerÃ­as utilizadas
- **Python 3.10+**
- **pandas / numpy**
- **matplotlib**
- **scikit-learn**
- **Google Colab**

---

## ğŸ§  Objetivos principales
1. Analizar la calidad y estructura de los datos del dataset `ramen-ratings.xlsx`.  
2. Limpiar y transformar los datos eliminando columnas irrelevantes y valores nulos.  
3. Crear una variable objetivo binaria (`Good` vs `Bad`) basada en las estrellas (`Stars`).  
4. Codificar las variables categÃ³ricas mediante `get_dummies`.  
5. Entrenar y comparar los modelos:
   - **RegresiÃ³n LogÃ­stica**
   - **Support Vector Machine (SVM)**  
6. Evaluar el desempeÃ±o con mÃ©tricas de clasificaciÃ³n (precision, recall, F1, AUC-ROC).

---

## ğŸ“Š Flujo de trabajo

### 1ï¸âƒ£ AnÃ¡lisis y limpieza de datos
- Se eliminÃ³ la columna `Top Ten` por contener **98.4% de valores nulos**.  
- `Stars` fue convertida a tipo numÃ©rico y los valores no vÃ¡lidos se imputaron con la mediana.  
- `Style` se rellenÃ³ con `"Unknown"`.  
- Se unificaron marcas poco frecuentes en la categorÃ­a `"Other"`.  

### 2ï¸âƒ£ CreaciÃ³n de la variable objetivo
Se definiÃ³ la variable binaria **`Rating`**:
```python
df['Rating'] = df['Stars'].apply(lambda x: 1 if x >= 3.5 else 0)

1 â†’ Ramen de buena calidad (â€œGoodâ€)
0 â†’ Ramen de baja calidad (â€œBadâ€)
3ï¸âƒ£ Preprocesamiento
Variables categÃ³ricas codificadas con pd.get_dummies.
EstandarizaciÃ³n mediante StandardScaler.
DivisiÃ³n entrenamiento/prueba 80/20.
ğŸ¤– Modelos y resultados
ğŸ”¹ RegresiÃ³n LogÃ­stica

| MÃ©trica      | Clase 0 (Bad) | Clase 1 (Good) | Global   |
| ------------ | ------------- | -------------- | -------- |
| PrecisiÃ³n    | 0.57          | 0.87           | -        |
| Recall       | 0.69          | 0.80           | -        |
| F1-Score     | 0.62          | 0.83           | -        |
| **Accuracy** |               |                | **0.77** |

ğŸ”¹ Support Vector Machine (SVM)

| MÃ©trica      | Clase 0 (Bad) | Clase 1 (Good) | Global   |
| ------------ | ------------- | -------------- | -------- |
| PrecisiÃ³n    | 0.54          | 0.89           | -        |
| Recall       | 0.74          | 0.76           | -        |
| F1-Score     | 0.63          | 0.82           | -        |
| **Accuracy** |               |                | **0.76** |
| **AUC-ROC**  |               |                | **0.85** |

ğŸ¯ Conclusiones
Ambos modelos presentan un desempeÃ±o sÃ³lido (76â€“77% de exactitud).
SVM logra una mejor discriminaciÃ³n general (AUC = 0.85), mostrando una ligera ventaja en capacidad predictiva.
RegresiÃ³n LogÃ­stica ofrece interpretabilidad y mayor recall para la clase â€œGoodâ€, ideal si se busca identificar productos de buena calidad con menor riesgo de omisiÃ³n.
El proyecto demuestra un flujo de clasificaciÃ³n supervisada completo, desde limpieza hasta evaluaciÃ³n comparativa de modelos.

