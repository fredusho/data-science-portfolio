# PRUEBA FINAL â€” Ventas ClassicModels: IntegraciÃ³n, KPIs y Reportes

**Resumen ejecutivo:**  
ConstrucciÃ³n de un pipeline analÃ­tico sobre la base **ClassicModels** en **PostgreSQL**, integrando tablas de pedidos, detalle, clientes, productos y empleados para generar un dataset desnormalizado, crear **mÃ©tricas de negocio** (venta, costo, ganancia), validar integridad referencial en los cruces y producir **reportes ejecutivos** (ventas por lÃ­nea de producto, clientes Ãºnicos, clientes sin compra, **Top 10 clientes** y **Top 10 productos** del **aÃ±o 2005**). Los reportes se **persisten en PostgreSQL**.

## ğŸ¯ Objetivos
- Ingerir datos de PostgreSQL y **unificar** las tablas: `orders`, `orderdetails`, `customers`, `products`, `employees`.
- **Validar integridad referencial** en cada merge (`validate=...`) para evitar duplicidades/errores.
- **Calcular KPIs** por transacciÃ³n:
  - `venta = quantityOrdered * priceEach`
  - `costo = quantityOrdered * buyPrice`
  - `ganancia = venta - costo`
- Responder preguntas de negocio:
  1) **Ventas por lÃ­nea de producto** (con fila de totales).  
  2) **Clientes distintos** que compraron.  
  3) **Clientes sin compras** (identificaciÃ³n y conteo).  
  4) **Reportes 2005**: Top 10 **clientes** y Top 10 **productos** (por cantidad y ventas), y **guardar** esos resultados en PostgreSQL.

## ğŸ—‚ï¸ Datos y modelo relacional
Fuente: **PostgreSQL â€“ esquema ClassicModels**  
Tablas utilizadas:
- `orders` (incluye `orderDate`, `customerNumber`)
- `orderdetails` (incluye `orderNumber`, `productCode`, `quantityOrdered`, `priceEach`)
- `customers` (incluye `customerNumber`)
- `products` (incluye `productCode`, `productName`, `productLine`, `buyPrice`)
- `employees` (incluye `employeeNumber`; mapeo vÃ­a `salesRepEmployeeNumber`)

> El dataset final integra contexto de **cliente**, **vendedor**, **producto** y **pedido** en un Ãºnico DataFrame para facilitar anÃ¡lisis.

## ğŸ§© MetodologÃ­a (alto nivel)
1. **ConexiÃ³n** a PostgreSQL con `SQLAlchemy` y lectura de tablas vÃ­a `pd.read_sql`.
2. **Cruces controlados** con `pd.merge(..., validate=...)`:
   - `orders âŸ¶ customers` (`many_to_one`)
   - `+ orderdetails` (`one_to_many`)
   - `+ products` (`many_to_one`)
   - `+ employees` (`many_to_one`, usando `salesRepEmployeeNumber`)
3. **Feature Engineering**: columnas `venta`, `costo`, `ganancia`.
4. **Agregaciones**:
   - `ventas_por_linea = final_df.groupby('productLine')['venta'].sum()`
   - Distintos clientes con compra.
   - Clientes **sin** compra (left-join/anti-join lÃ³gico).
5. **Filtro temporal 2005** con helper `filtrar_por_fecha(final_df, 'orderDate', '2005-01-01', '2005-12-31')`.
6. **Reportes ejecutivos** con helper `generar_reporte_pivot(...)` para resumir:
   - **Top 10 clientes 2005**
   - **Top 10 productos 2005**
7. **Persistencia** a PostgreSQL con helper `guardar_en_postgre(df, nombre_tabla, engine)`.

## ğŸ“Œ Resultados clave
- **Ventas por lÃ­nea de producto**: tabla consolidada con **fila de totales**.
- **Clientes Ãºnicos con compra**: conteo directo desde el dataset integrado.
- **Clientes sin compra**: identificaciÃ³n y total.
- **Top 10 (2005)**:
  - **Clientes** por `quantityOrdered` y `venta`.
  - **Productos** por `quantityOrdered` y `venta`.
- Resultados persistidos en PostgreSQL (tablas sugeridas):
  - `top_10_clientes_2005`
  - `top_10_productos_2005`

> Nota: Las tablas finales se crean/actualizan en la misma base objetivo definida en el `engine`.

## ğŸ› ï¸ Stack tecnolÃ³gico
- **Python**: `pandas`, `numpy`, `math`
- **Base de datos**: **PostgreSQL**
- Conectividad: `sqlalchemy`, `psycopg2`
- (Helpers) MÃ³dulo `funciones` con:
  - `filtrar_por_fecha(df, col, desde, hasta)`
  - `generar_reporte_pivot(df, filas, columnas, valores, funcion_agrupadora)`
  - `guardar_en_postgre(df, nombre_tabla, engine)`

## ğŸ“ Estructura sugerida del proyecto
.
â”œâ”€â”€ notebook.ipynb
â”œâ”€â”€ src/
â”‚ â””â”€â”€ funciones.py # helpers: filtrar_por_fecha, generar_reporte_pivot, guardar_en_postgre
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ DATA_INSTRUCTIONS.md # cÃ³mo descargar datos si aplica
â”‚ â””â”€â”€ (muestras pequeÃ±as .csv si son <50MB)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


## âš™ï¸ ConfiguraciÃ³n y ejecuciÃ³n

### 1) Variables de conexiÃ³n
En el notebook:
```python
db_url = "postgresql://USUARIO:PASS@HOST:PUERTO/NOMBRE_BASE"
engine = create_engine(db_url)

