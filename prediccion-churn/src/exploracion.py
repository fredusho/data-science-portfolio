# -*- coding: utf-8 -*-
"""exploracion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tguPdTFgsvEvq3CK85Y7OMw2DXH7fxpV
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, chi2_contingency

def calidad_datos(datos):
    """
    Evalúa la calidad de los datos de un DataFrame.

    Retorna un DataFrame con:
    - Tipo de dato de cada columna.
    - Cantidad y porcentaje de valores nulos.
    - Cantidad y porcentaje de ceros.
    - Estadísticas descriptivas generales.
    - Límites para detectar valores atípicos con IQR.
    - Conteo de valores atípicos.
    """
    if datos.empty:
        return "El DataFrame está vacío."

    tipos = pd.DataFrame(datos.dtypes, columns=['tipo'])
    nan = pd.DataFrame(datos.isna().sum(), columns=['nan'])
    nan_prop = pd.DataFrame((datos.isna().sum() / datos.shape[0]) * 100, columns=['porcentaje_nan'])

    ceros = pd.DataFrame({col: (datos[col] == 0).sum() for col in datos.columns}, index=['ceros']).T
    ceros_prop = pd.DataFrame({col: ((datos[col] == 0).sum() / datos.shape[0]) * 100 for col in datos.columns}, index=['porcentaje_ceros']).T

    resumen = datos.describe(include='all').T
    resumen['IQR'] = resumen['75%'] - resumen['25%']
    resumen['lim_inf'] = resumen['25%'] - 1.5 * resumen['IQR']
    resumen['lim_sup'] = resumen['75%'] + 1.5 * resumen['IQR']

    # Contar valores atípicos
    resumen['atipicos'] = datos.apply(
        lambda x: sum((x < resumen['lim_inf'][x.name]) | (x > resumen['lim_sup'][x.name]))
        if x.name in resumen['lim_inf'].dropna().index else 0
    )

    return pd.concat([tipos, nan, nan_prop, ceros, ceros_prop, resumen], axis=1).sort_values('tipo')


def graficos(calidad, datos, cols, max_categoricas=20):
    """
    Genera gráficos de distribución para variables numéricas y de conteo para variables categóricas.

    Parámetros:
    - calidad: DataFrame con información de calidad de los datos.
    - datos: DataFrame con los datos originales.
    - cols: Lista de columnas a graficar.
    - max_categoricas: Número máximo de categorías a mostrar en gráficos de barras.
    """
    num_cols = len(cols)
    num_rows = (num_cols + 2) // 3
    plt.figure(figsize=(15, 3 * num_rows))

    for n, col in enumerate(cols):
        plt.subplot(num_rows, 3, n+1)

        if calidad.loc[col, 'tipo'] == 'object':
            sns.countplot(y=datos[col], order=datos[col].value_counts().iloc[:max_categoricas].index)
            plt.title(f'Frecuencias para {col}')
        else:
            sns.histplot(datos[col], kde=True)
            plt.title(f'Distribución para {col}')

        plt.tight_layout()


def no_atipicos(columna):
    """
    Filtra valores que no son atípicos según el rango intercuartílico (IQR).

    Retorna una serie booleana con True para valores no atípicos y False para atípicos.
    """
    if columna.isnull().all():
        return columna.notna()  # Retorna todo False si la columna es completamente NaN

    q1, q3 = columna.quantile([0.25, 0.75])
    rango_iq = q3 - q1
    lim_inf, lim_sup = q1 - 1.5 * rango_iq, q3 + 1.5 * rango_iq

    return (columna >= lim_inf) & (columna <= lim_sup)


def correlacion(datos, target):
    """
    Calcula correlaciones entre las variables del DataFrame y una variable objetivo.

    - Para variables numéricas, calcula la correlación de Pearson.
    - Para variables categóricas, realiza la prueba de Chi-cuadrado.

    Retorna una lista de variables numéricas y categóricas analizadas.
    """
    if target not in datos.columns:
        return f"Error: La columna '{target}' no existe en el DataFrame."

    numeric_features = datos.select_dtypes(include=[np.number]).columns.tolist()

    for feature in numeric_features:
        dfi = datos[[feature, target]].dropna()
        if dfi.shape[0] > 1:
            corr, _ = pearsonr(dfi[feature], dfi[target])
            print(f"Correlación de Pearson entre {feature} y {target}: {corr:.2f}")

    categorical_features = datos.select_dtypes(include=['object', 'category']).columns.tolist()

    for feature in categorical_features:
        if datos[target].nunique() == 2:  # Convertimos target a binario si es categórico
            target_modificado = datos[target].astype(str)
            tabla_contingencia = pd.crosstab(datos[feature], target_modificado)
            chi2, p, _, _ = chi2_contingency(tabla_contingencia)

            if p < 0.05:
                print(f"Chi-cuadrado entre {feature} y {target}: {chi2:.2f}, p-value: {p:.4f}. Relación significativa.")
            else:
                print(f"Chi-cuadrado entre {feature} y {target}: {chi2:.2f}, p-value: {p:.4f}. No hay relación.")

    return numeric_features, categorical_features