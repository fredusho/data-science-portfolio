[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fredusho/data-science-portfolio/blob/main/prediccion-churn/prediccion-churn.ipynb)

# Predicci√≥n de Fuga de Clientes (Churn Prediction)

## üß© Descripci√≥n del proyecto
Este proyecto implementa un modelo de **aprendizaje supervisado para predecir la fuga de clientes (churn)** en una empresa de telecomunicaciones, utilizando t√©cnicas de clasificaci√≥n con Python y scikit-learn.  
El objetivo es identificar a los clientes con mayor probabilidad de abandonar el servicio, apoyando estrategias de retenci√≥n y marketing personalizado.

---

## ‚öôÔ∏è Tecnolog√≠as y librer√≠as utilizadas
- **Python 3.10+**
- **pandas / numpy**
- **matplotlib / seaborn**
- **scikit-learn**
- **Google Colab**

---

## üß† Objetivos principales
1. Analizar y limpiar el dataset `Telco-Customer-Churn.xlsx`.  
2. Preparar los datos mediante **codificaci√≥n, normalizaci√≥n y manejo de valores nulos**.  
3. Entrenar y comparar tres modelos de clasificaci√≥n:
   - **Regresi√≥n Log√≠stica**
   - **√Årbol de Decisi√≥n**
   - **Random Forest**
4. Evaluar el rendimiento con m√©tricas de clasificaci√≥n, precisi√≥n y AUC-ROC.  
5. Determinar el modelo m√°s eficiente para predecir la fuga de clientes.

---

## üìä Flujo de trabajo

### 1Ô∏è‚É£ An√°lisis exploratorio y calidad de datos
- Dataset con **7.043 registros** y **20 columnas** (num√©ricas y categ√≥ricas).  
- Solo la columna `TotalCharges` present√≥ 11 valores nulos (0.16%).  
- Se detectaron y eliminaron columnas irrelevantes como `customerID`.  
- Codificaci√≥n de variables categ√≥ricas con `LabelEncoder`.  
- Estandarizaci√≥n de variables num√©ricas (`tenure`, `MonthlyCharges`, `TotalCharges`) mediante `StandardScaler`.

### 2Ô∏è‚É£ Divisi√≥n del dataset
- 80% entrenamiento / 20% prueba, estratificado por la variable `Churn`.  
- Distribuci√≥n de clases: **73.4% no fugados**, **26.6% fugados**.

### 3Ô∏è‚É£ Entrenamiento y optimizaci√≥n
Modelos entrenados con **GridSearchCV** y validaci√≥n cruzada (5 folds).  
- **Regresi√≥n Log√≠stica:** mejor configuraci√≥n ‚Üí `C=0.01, penalty='l2', solver='saga'`.  
- **√Årbol de Decisi√≥n:** `max_depth=5, min_samples_leaf=2, min_samples_split=10`.  
- **Random Forest:** `n_estimators=50, max_depth=10, min_samples_leaf=2, min_samples_split=10`.

### 4Ô∏è‚É£ Resultados de rendimiento

| Modelo | Accuracy | AUC-ROC | Especificidad | Comentario |
|--------|-----------|----------|----------------|-------------|
| Regresi√≥n Log√≠stica | 0.787 | 0.829 | 0.892 | Buen equilibrio entre precisi√≥n y recall |
| √Årbol de Decisi√≥n | 0.782 | 0.819 | 0.884 | Modelo interpretable, menor generalizaci√≥n |
| Random Forest | **0.790** | **0.833** | **0.899** | Mejor desempe√±o global y estabilidad |

---

## üéØ Conclusiones
- El modelo de **Random Forest** obtuvo los mejores resultados (AUC = 0.833, Accuracy = 79%).  
- Todos los modelos mostraron un **alto desempe√±o en la clase ‚Äúno fugado‚Äù**, pero dificultades para identificar correctamente a los clientes que s√≠ se fugan.  
- Se recomienda:
  - Ajustar el umbral de clasificaci√≥n.  
  - Aplicar t√©cnicas de **balanceo de clases (SMOTE o undersampling)**.  
  - Evaluar modelos m√°s complejos como **XGBoost** o **LightGBM**.



